{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DM-35166 Clean up annotation tags in SQuaSH\n",
    "See also [annotation guidelines](https://confluence.lsstcorp.org/display/DM/SQuaSH+Annotations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the SQuaSH instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from aioinflux import InfluxDBClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFLUXDB_URL = \"influxdb-demo.lsst.codes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See SQuaSH InfluxDB user credentials in SQuaRE 1Password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "username = \"squash\"\n",
    "password = getpass.getpass(prompt='Password for user `{}`: '.format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Query `chronograf-sandbox`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`chronograf-sandbox` is a copy of the `chronograf` database which contains the annotations data. The following query was used to create `chronograf-sandbox`:\n",
    "```\n",
    "> SELECT * INTO \"chronograf-sandbox\".autogen.:MEASUREMENT FROM \"chronograf\".autogen./.*/ GROUP BY *\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InfluxDBClient(host=INFLUXDB_URL, port=443, ssl=True, db=\"chronograf-sandbox\", username=username, password=password, output=\"dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve annotations, skip deleted ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = await client.query(f\"SELECT * FROM annotations WHERE deleted!=True\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up tag keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Remove `brightSnrMin`, `Feature` and `nMinPhotRepeat` tag keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=[\"brightSnrMin\", \"Feature\", \"nMinPhotRepeat\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Merge  `:Dataset:`, `ci_dataset`, `Dataset` into `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Dataset\"] = df[[\":Dataset:\", \"Dataset\", \"ci_dataset\"]].apply(lambda x: x[0] or x[1] or x[2], axis=1)\n",
    "df = df.drop(columns=[\":Dataset:\", \"ci_dataset\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merge `Pipeline`, `Pipeliine`, `pipeline`, `Pipelines` into `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Pipeline\"] = df[[\"Pipeline\", \"Pipeliine\", \"pipeline\", \"Pipelines\"]].apply(lambda x: x[0] or x[1] or x[2] or x[3], axis=1)\n",
    "df = df.drop(columns=[\"pipeline\", \"Pipeliine\", \"Pipelines\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Replace `faro=Pipeline` with `Pipeline=DRP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"faro\"] == \"Pipeline\", \"Pipeline\"] = \"DRP\"\n",
    "df = df.drop(columns=[\"faro\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up Dataset tag values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Replace `CI-HiTS2015` and `HiTS2015` with `ap_verify_ci_hits2015`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Dataset\"] == \"CI-HiTS2015\", \"Dataset\"] = \"ap_verify_ci_hits2015\"\n",
    "df.loc[df[\"Dataset\"] == \"HiTS2015\", \"Dataset\"] = \"ap_verify_ci_hits2015\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up `Pipeline` tag values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Replace `ap_pipe` with `AP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Pipeline\"] == \"ap_pipe\", \"Pipeline\"] = \"AP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Replace `hsc` with `Pipeline=DRP` and `Dataset=hsc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Pipeline\"] == \"hsc\", \"Dataset\"]=\"hsc\"\n",
    "df.loc[df[\"Pipeline\"] == \"hsc\", \"Pipeline\"]=\"DRP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Replace `faro, pipe_analysis` with `DRP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Pipeline\"] == \"faro\", \"Pipeline\"] = \"DRP\"\n",
    "df.loc[df[\"Pipeline\"] == \"pipe_analysis\", \"Pipeline\"] = \"DRP\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix up invalid text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"id\"]==\"a1b2aa82-31f2-4c72-9c5d-40c103829046\",\"text\"] = \"DM-17413: background tweak to detection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write annotations df to a new measurement in `chronograf-sandbox`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle sparse Dataframe\n",
    "\n",
    "Tags are optional in InfluxDB and so tags with value `None` in the dataframe should be removed from the point before writing to InfluxDB. Otherwise \"None\" would be recorded as tag value (string) and that's not what we want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "for i in range(len(df)):\n",
    "    row=df.iloc[[i]]\n",
    "    tag_columns = [\"id\"]\n",
    "    drop_columns = []\n",
    "    \n",
    "    if row[\"Dataset\"].iloc[0] is None:\n",
    "        drop_columns.append(\"Dataset\")\n",
    "    else:\n",
    "        tag_columns.append(\"Dataset\")\n",
    "        \n",
    "    if row[\"Gen\"].iloc[0] is None:       \n",
    "        drop_columns.append(\"Gen\")\n",
    "    else:\n",
    "        tag_columns.append(\"Gen\") \n",
    "        \n",
    "    if row[\"Instrument\"].iloc[0] is None:\n",
    "        drop_columns.append(\"Instrument\")\n",
    "    else:\n",
    "        tag_columns.append(\"Instrument\")\n",
    "        \n",
    "    if row[\"Pipeline\"].iloc[0] is None:\n",
    "        drop_columns.append(\"Pipeline\")\n",
    "    else:\n",
    "        tag_columns.append(\"Pipeline\")\n",
    "        \n",
    "    row_df = row.drop(columns=drop_columns)\n",
    "    \n",
    "    await client.write(row_df, measurement=\"annotations_clean\", tag_columns=tag_columns)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
