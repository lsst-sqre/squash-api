{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQuaSH InfluxDB data model\n",
    "\n",
    "In [DM-16775](https://github.com/lsst-sqre/squash-restful-api/tree/master/examples/influxdb_data_model.ipynb) we revisit the SQuaSH InfluxDB data model. You can use this notebook to try different strategies mapping SQuaSH data to InfluxDB. You can also use it to \"manually\" synchronize the SQuaSH production database with an InfluxDB instance. For a quick introduction on InfluxDB concepts see [this notebook](https://github.com/lsst-sqre/influx-demo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUASH_API_URL = \"https://squash-restful-api.lsst.codes/\"\n",
    "INFLUXDB_API_URL = \"https://influxdb-demo.lsst.codes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells will grab SQuaSH data and write it in the format used by InfluxDB, the so called [line protocol](https://docs.influxdata.com/influxdb/v1.6/write_protocols/line_protocol_tutorial/):\n",
    "\n",
    "\n",
    "```#<measurement>[,<tag_key>=<tag_value>[,<tag_key>=<tag_value>]] <field_key>=<field_value>[,<field_key>=<field_value>] [<timestamp>]```\n",
    "\n",
    "Important InfluxDB concepts: an InfluxDB measurement is equivalent to an SQL table, tags are annotations that are used to query the data, and thus are indexed in InfluxDB. Fields correspond to the actual values (metric values, ci_id, run_id, etc.) and are not indexed. InfluxDB is optimized for time-series data which are indexed and sharded by the timestamp.\n",
    "\n",
    "## Mapping lsst.verify concepts to InfluxDB\n",
    "\n",
    "`lsst.verify` concepts are mapped as follow:\n",
    "\n",
    "* lsst.verify package -> InfluxDB measurement\n",
    "* lsst.verify metadata -> InfluxDB tag\n",
    "* lsst.verify metric value - > InfluxDB field\n",
    "* CI or LDF pipeline runtime -> InfluxDB timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping SQuaSH metadata to InfluxDB\n",
    "`lsst.verify` adds metadata to the verification jobs uploaded to SQuaSH. The mapping of these metadata to either InfluxDB tags or fields is defined here:\n",
    "\n",
    "1. By default, if the SQuaSH metadata key is not found in the mapping, the original key will be preserved and it will be written to InfluxDB as a tag.\n",
    "2. You can use the mapping to rename the metadata key when appropriate. \n",
    "3. Finally, if `schema` is set to `None`, then the corresponding metadata won't be written to InfluxDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = [{'squash': 'ci_id',  # The ID of the execution environment is mapped to run_id\n",
    "            'influxdb': 'run_id', \n",
    "            'schema': 'field'\n",
    "           },\n",
    "           {'squash': 'run_id',\n",
    "            'influxdb': 'run_id',\n",
    "            'schema': 'field'\n",
    "           },\n",
    "            {'squash': 'id',  \n",
    "            'influxdb': 'squash_id',\n",
    "            'schema': 'field'\n",
    "           },\n",
    "            {'squash': 'url',\n",
    "             'influxdb': 'squash_url',\n",
    "             'schema': 'field',\n",
    "             'transformation': \"format_url(data['id'], value)\"\n",
    "            },\n",
    "           {'squash': 'run_id_url', # The URL of the execution environment is mapped to run_url\n",
    "            'influxdb': 'run_url',\n",
    "            'schema': 'field',\n",
    "            'transformation': \"format_url(data['run_id'], value)\"\n",
    "           },\n",
    "           {'squash': 'ci_url',\n",
    "            'influxdb': 'run_url',\n",
    "            'schema': 'field',\n",
    "            'transformation': \"format_url(data['ci_id'], value)\"\n",
    "           },\n",
    "           {'squash': 'ci_dataset', # The processed dataset is mapped to dataset\n",
    "            'influxdb': 'dataset',\n",
    "            'schema': 'tag'\n",
    "           },\n",
    "           {'squash': 'version_tag', \n",
    "            'influxdb': 'version_tag',\n",
    "            'schema': 'field'\n",
    "           },\n",
    "           {'squash': 'filter_name',\n",
    "            'influxdb': 'filter',\n",
    "            'schema': 'tag'\n",
    "           },\n",
    "           {'squash': 'date_created',\n",
    "            'influxdb': 'timestamp',\n",
    "            'schema': 'field',\n",
    "            'transformation': 'format_timestamp(value)'\n",
    "           },\n",
    "           {'squash': 'date', \n",
    "            'influxdb': None,\n",
    "            'schema': None\n",
    "           },\n",
    "           {'squash': 'ci_label',\n",
    "            'influxdb': None,\n",
    "            'schema': None\n",
    "           },\n",
    "           {'squash': 'ci_name',\n",
    "            'influxdb': None,\n",
    "            'schema': None\n",
    "           },\n",
    "           {'squash': 'packages',\n",
    "            'influxdb': None,\n",
    "            'schema': None\n",
    "           },\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rationale for this mapping is the following:\n",
    "1. `ci_id`, `run_id` and `squash_id` are sequential numbers. `ci_url` and `run_id_url` are different for each run. The reason for adding them as InfluxDB fields is to [reduce InfluxDB series cardinality](https://docs.influxdata.com/influxdb/v1.7/concepts/schema_and_data_layout/#discouraged-schema-design) (DM-18342)\n",
    "2. We define a common datamodel mapping variables from different execution environments example `ci_id` and `run_id` to `run_id`, `ci_url` and `run_id_url` to `run_url`, `ci_dataset` and `dataset` to `dataset`. The corresponding values can be filtered by the `env_name` tag. \n",
    "3. It is not possible to do [math operations with InfluxDB timestamps](https://community.influxdata.com/t/math-operations-on-field-value-and-time/6323/4) so it is useful to add the `timestamp` explicitly as a field. There's also a `date` field which is added as environment metadata that we don't need in InfluxDB (DM-17049)\n",
    "4. `lsst.verify` metadata uses `filter_name`. We decided to rename it since it is commonly called filter in the dataID used in processing with DM software.\n",
    "5. `ci_label` and `ci_name` does not seem important so we skip those. \n",
    "6. We also skip `packages` metadata for now. The plan is to add to InfluxDB the packages that changed between two consecutive CI runs and display that in a Chronograf table (DM-18343)\n",
    "7. Other metadata are automatically added as InfluxDB tags.\n",
    "\n",
    "\n",
    "See also [InfluxDB schema design and data layout](https://docs.influxdata.com/influxdb/v1.7/concepts/schema_and_data_layout/#general-recommendations) recommendations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a new InfluxDB database. If the database already exists, an status code 200 (OK) is returned, and the existing data is preserved. If you want to overwrite an existing database you have to delete it first using the Chronograf admin interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "INFLUXDB_DATABASE = \"test\"\n",
    "\n",
    "params={'q': 'CREATE DATABASE \"{}\"'.format(INFLUXDB_DATABASE)}\n",
    "r = requests.post(url=INFLUXDB_API_URL + \"/query\", params=params)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytz import UTC\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def format_timestamp(date):\n",
    "    \"\"\" Format a timestamp string to be used in the InfluxDB line protocol.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        date: `<str>`\n",
    "            Timestamp string, e.g. 2019-02-11T19:06:32Z\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        timestamp: `<int>`\n",
    "            Timestamp in nanosecond-precision Unix time.\n",
    "            See https://docs.influxdata.com/influxdb/v1.6/write_protocols/\n",
    "    \"\"\"\n",
    "\n",
    "    epoch = UTC.localize(datetime.utcfromtimestamp(0))\n",
    "\n",
    "    timestamp = int((parse(date) - epoch).total_seconds() * 1e9)\n",
    "\n",
    "    return timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_url(id, url):\n",
    "    return \"[{}]({})\".format(id, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(key):\n",
    "    \"\"\" Perform the mapping between SQuaSH metadata and InfluxDB \n",
    "        given a MAPPING.\n",
    "    \n",
    "        Parameters\n",
    "        ---------- \n",
    "        key: `str`\n",
    "            The key to look for in the MAPPING.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        mapped_key: `str` or `None`       \n",
    "            Returns the `mapped_key` if the key is found in the MAPPING or the \n",
    "            original key if the key does not match.\n",
    "       \n",
    "        schema: `str` or `None`\n",
    "            The InfluxDB schema to write, or `None` if the key should not \n",
    "            be added to InfluxDB. \n",
    "        \n",
    "        \n",
    "    \"\"\" \n",
    "    schema = 'tag'\n",
    "    mapped_key = key\n",
    "    transformation = None\n",
    "    \n",
    "    for m in MAPPING:\n",
    "        if m['squash'] == key:\n",
    "            mapped_key = m['influxdb']\n",
    "            schema = m['schema']\n",
    "            if 'transformation' in m:\n",
    "                transformation = m['transformation']\n",
    "            break\n",
    "                \n",
    "    return schema, mapped_key, transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(obj):\n",
    "    \"\"\" Return a valid string representing a tag key, a tag value or a field key.\n",
    "        \n",
    "        See https://docs.influxdata.com/influxdb/v0.13/write_protocols/\n",
    "        write_syntax/#escaping-characters\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        obj: `<obj>`\n",
    "            An object for the tag key, tag value or field key.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        string: `str`\n",
    "            A valid string for the tag key, tag value or field key.\n",
    "    \"\"\"\n",
    "    string = str(obj)\n",
    "    string = string.replace(\" \", \"\\ \")\n",
    "    string = string.replace(\",\", \"\\,\" )\n",
    "    string = string.replace(\"=\", \"\\=\")\n",
    "            \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_metadata(data):\n",
    "    \"\"\" Process SQuaSH metadata using a pre-configured mapping to InfluxDB.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: `dict`\n",
    "            A dictionary with SQuaSH metadata.\n",
    "       \n",
    "        Return\n",
    "        ------\n",
    "        tags: `<list>` \n",
    "            List of tags to be written to InfluxDB.\n",
    "        fields: `<list>`\n",
    "            List of fields to be written to InfluxDB.\n",
    "    \"\"\"\n",
    "    tags = []\n",
    "    fields = []\n",
    "    for key, value in data.items():\n",
    "        # process nested dict\n",
    "        if isinstance(value, dict):\n",
    "            tmp_tags, tmp_fields = process_metadata(value)\n",
    "            tags.extend(tmp_tags)\n",
    "            fields.extend(tmp_fields)\n",
    "        else:\n",
    "            schema, mapped_key, transformation = mapping(key)\n",
    "            if transformation:\n",
    "                value = eval(transformation)\n",
    "            if mapped_key and schema == 'tag':\n",
    "                tags.append(\"{}={}\".format(sanitize(mapped_key), sanitize(value)))\n",
    "            elif mapped_key and schema == 'field':\n",
    "                if isinstance(value, str):\n",
    "                    fields.append(\"{}=\\\"{}\\\"\".format(sanitize(mapped_key), value))\n",
    "                else:\n",
    "                    fields.append(\"{}={}\".format(sanitize(mapped_key), value))\n",
    "    \n",
    "    return tags, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_influxdb_line(measurement, tags, fields, timestamp):\n",
    "    \"\"\" Format a line following the InfluxDB line protocol.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        measurement: `<str>`\n",
    "            Name of the InfluxDB measurement\n",
    "        tags: `<list>`\n",
    "            A list of valid InfluxDB tags\n",
    "        fields: `<list>`\n",
    "            A list of valid InfluxDB fields\n",
    "        timestamp: `int`\n",
    "            A timestamp in nanosecond-precision Unix time.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        influxdb_line: `<str>`\n",
    "            An InfluxDB line as defined by the line protocol in\n",
    "            https://docs.influxdata.com/influxdb/v1.6/write_protocols/\n",
    "    \"\"\"\n",
    "    line = \"{},{} {} {}\".format(measurement, \",\".join(tags), \",\".join(fields),\n",
    "                                timestamp)\n",
    "    return line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_influxdb(influxdb_line):\n",
    "    \"\"\" Send a line to an InfluxDB database. It assumes INFLUXDB_DATABASE already\n",
    "        exists in InfluxDB.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        influxdb_line: `<str>`\n",
    "            An InfluxDB line as defined by the line protocol in\n",
    "            https://docs.influxdata.com/influxdb/v1.6/write_protocols/\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        status_code: `<int>`\n",
    "            Status code from the InfluxDB HTTP API.\n",
    "        text: `<str>`\n",
    "            Status message from the InfluxDB HTTP API.\n",
    "    \"\"\"\n",
    "    params = {'db': INFLUXDB_DATABASE}\n",
    "    r = requests.post(url=INFLUXDB_API_URL + \"/write\", params=params,\n",
    "                      data=influxdb_line)\n",
    "\n",
    "    return r.status_code, r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import urllib.parse\n",
    "\n",
    "def job_to_influxdb(data):\n",
    "    \"\"\"Unpack a SQuaSH job and send it to InfluxDB. \n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: `<dict>`\n",
    "            A dictionary containing the job data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        status_code: `<int>`\n",
    "             204:\n",
    "               The request was processed successfully\n",
    "             400:\n",
    "               Malformed syntax or bad query\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        `lsst.verify` measurement and InfluxDB measurement mean different things. \n",
    "    \"\"\"    \n",
    "    # This still gets the timestamp of an individual `lsst.verify` job, we want \n",
    "    # the timestamp of the Jenkins job instead.\n",
    "    # DM-18359 - SQuaSH API /jenkins/<ci_id> should return the jenkins timestamp \n",
    "    \n",
    "    timestamp = format_timestamp(data['date_created'])\n",
    "    \n",
    "    # Add extra metadata\n",
    "    \n",
    "    data['meta']['id'] = data['id']\n",
    "    \n",
    "    data['meta']['url'] = urllib.parse.urljoin(SQUASH_API_URL, \n",
    "                                               \"/job/{}\".format(data['id']))\n",
    "\n",
    "    data['meta']['date_created'] = data['date_created']\n",
    "    data['meta']['env']['ci_dataset'] = data['ci_dataset']\n",
    "    \n",
    "    # Edge cases that we cannot handle in the mapping\n",
    "    \n",
    "    # Fix dataset_repo_url duplication\n",
    "    if 'dataset_repo_url' in data['meta'].keys():\n",
    "        del data['meta']['dataset_repo_url']\n",
    "    \n",
    "    # Fix use of ci_dataset key in environments other than jenkins\n",
    "    if data['meta']['env']['env_name'] != 'jenkins':\n",
    "        if 'ci_dataset' in data['meta']['env']:\n",
    "            del data['meta']['env']['ci_dataset']\n",
    "    \n",
    "    tags, extra_fields = process_metadata(data['meta'])\n",
    "    \n",
    "    \n",
    "    # `lsst.verify` package -> InfluxDB measurement\n",
    "    # `lsst.verify` metric value -> InfluxDB field\n",
    "    # Group InfluxDB fields by the corresponding InfluxDB measurement\n",
    "    \n",
    "    fields_by_measurement = {}\n",
    "    for verify_measurement in data['measurements']:\n",
    "        # DM-18360 - SQuaSH API /measurements should return the verification package \n",
    "        influxdb_measurement = verify_measurement['metric'].split('.')[0]\n",
    "\n",
    "        if influxdb_measurement not in fields_by_measurement:\n",
    "            fields_by_measurement[influxdb_measurement] = []\n",
    "            \n",
    "        # InfluxDB does not store NaNs\n",
    "        # https://github.com/influxdata/influxdb/issues/4089\n",
    "        if not math.isnan(verify_measurement['value']):\n",
    "            fields_by_measurement[influxdb_measurement].append(\"{}={}\".format(verify_measurement['metric'],\n",
    "                                                                              verify_measurement['value']))\n",
    "    \n",
    "    # By grouping InfluxDB fields we can also send all fields that belong to a \n",
    "    # measurement at once.\n",
    "    for influxdb_measurement in fields_by_measurement:\n",
    "    \n",
    "        fields = fields_by_measurement[influxdb_measurement] + extra_fields\n",
    "        influxdb_line = format_influxdb_line(influxdb_measurement, tags, fields,\n",
    "                                             timestamp)\n",
    "\n",
    "        status_code, message = send_to_influxdb(influxdb_line)\n",
    "        if status_code != 204:\n",
    "            print(message)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a list of verification jobs from SQuaSH and send them to InfluxDB. As you run this notebook you might follow the data being written to InfluxDB using the [Data Explorer tool](https://chronograf-demo.lsst.codes/) in Chronograf. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = requests.get(SQUASH_API_URL + \"/jobs\").json()\n",
    "\n",
    "for job_id in jobs['ids']:\n",
    "    \n",
    "    data = requests.get(SQUASH_API_URL + \"/job/{}\".format(job_id)).json()\n",
    "    \n",
    "    # Skip deprecated datasets\n",
    "    if data['ci_dataset'] == 'unknown' or data['ci_dataset'] == 'decam':\n",
    "        continue\n",
    "\n",
    "    print('Sending InfluxDB line for job {}.'.format(job_id))\n",
    "    \n",
    "    job_to_influxdb(data)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
