{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQuaSH InfluxDB data model\n",
    "\n",
    "In [DM-18103](https://jira.lsstcorp.org/browse/DM-18103) we revisit the SQuaSH InfluxDB data model. You can use this notebook to try different strategies mapping `lsst.verify` data to InfluxDB. You can also use it to \"manually\" synchronize the SQuaSH production database with an InfluxDB instance. For a quick introduction on InfluxDB concepts see [this notebook](https://github.com/lsst-sqre/influx-demo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUASH_API_URL = \"https://squash-restful-api.lsst.codes/\"\n",
    "INFLUXDB_API_URL = \"https://influxdb-demo.lsst.codes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells will grab SQuaSH data and write it in the format used by InfluxDB, the so called [line protocol](https://docs.influxdata.com/influxdb/v1.6/write_protocols/line_protocol_tutorial/):\n",
    "\n",
    "\n",
    "```#<measurement>[,<tag_key>=<tag_value>[,<tag_key>=<tag_value>]] <field_key>=<field_value>[,<field_key>=<field_value>] [<timestamp>]```\n",
    "\n",
    "Important InfluxDB concepts: an InfluxDB measurement is equivalent to an SQL table, tags are annotations that are used to query the data, and thus are indexed in InfluxDB. Fields correspond to the actual values (metric values in this case) and are not indexed. InfluxDB is optimized for time-series data which are indexed and sharded by the timestamp.\n",
    "\n",
    "\n",
    "See also [InfluxDB schema design and data layout](https://docs.influxdata.com/influxdb/v1.7/concepts/schema_and_data_layout/#general-recommendations) recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping SQuaSH metadata to InfluxDB\n",
    "`lsst.verify` adds metadata to verification jobs and this is uploaded to SQuaSH. The mapping this metadata to either InfluxDB tags or fields is defined by this mapping:\n",
    "\n",
    "1. By default, if the SQuaSH metadata key is not found in the mapping, it will be written as a tag, and the original key will be preserved. \n",
    "2. You can use the mapping to rename the metadata key when appropriate. \n",
    "3. Finally, if `schema` is set to `None` in the mapping, then the corresponding metadata won't be written to InfluxDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = [{'squash': 'ci_id', \n",
    "            'influxdb': 'ci_id', \n",
    "            'schema': 'field'\n",
    "           },\n",
    "           {'squash': 'id', \n",
    "            'influxdb': 'squash_id',\n",
    "            'schema': 'field'\n",
    "           },\n",
    "           {'squash': 'date',\n",
    "            'influxdb': None,\n",
    "            'schema': None\n",
    "           },\n",
    "           {'squash': 'timestamp',\n",
    "            'influxdb': 'timestamp',\n",
    "            'schema': 'field'\n",
    "           },\n",
    "           {'squash': 'ci_url',\n",
    "            'influxdb': None,\n",
    "            'schema': None\n",
    "           },\n",
    "           {'squash': 'packages',\n",
    "            'influxdb': None,\n",
    "            'schema': None\n",
    "           },\n",
    "           {'squash': 'filter_name',\n",
    "            'influxdb': 'filter',\n",
    "            'schema': 'tag'\n",
    "           }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rationale for this mapping is the following:\n",
    "1. `ci_id` and `squash_id` are sequential numbers if they are mapped to InfluxDB tag it will [increase InfluxDB series cardinality](https://docs.influxdata.com/influxdb/v1.7/concepts/schema_and_data_layout/#discouraged-schema-design) (DM-18342)\n",
    "2. It is not possible to do [math operations with InfluxDB timestamps](https://community.influxdata.com/t/math-operations-on-field-value-and-time/6323/4) so it is useful to add the `timestamp` explicitly as a field. There are also a `date` field which is added as environment metadata that we don't need in InfluxDB (DM-17049)\n",
    "3. `ci_url` will be used to connected Chronograf to CI. It is a different URL for each CI run. The rationale for adding `ci_url` as an InfluxDB field it is the same as in 1 (DM-18342)\n",
    "4. We skip `packages` metadata for now, we plan to add to InfluxDB only the packages that changed between two consecutive CI runs (DM-18343)\n",
    "5. `lsst.verify` metadata uses `filter_name` we decided to rename it to `filter` is the dataID key commonly used in DM.\n",
    "6. Other metadata are automatically added as InfluxDB tags.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a new InfluxDB database. Note that if the database already exists an status code 200 (OK) is returned and the existing data is preserved. If you want to overwrite an existing database you have to delete it first using the Chronograf admin interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "INFLUXDB_DATABASE = \"squash-demo\"\n",
    "\n",
    "params={'q': 'CREATE DATABASE \"{}\"'.format(INFLUXDB_DATABASE)}\n",
    "r = requests.post(url=INFLUXDB_API_URL + \"/query\", params=params)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytz import UTC\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def format_timestamp(date):\n",
    "    \"\"\" Format a timestamp string to be used in the InfluxDB line protocol.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        date: `<str>`\n",
    "            Timestamp string, e.g. 2019-02-11T19:06:32Z\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        timestamp: `<int>`\n",
    "            Timestamp in nanosecond-precision Unix time.\n",
    "            See https://docs.influxdata.com/influxdb/v1.6/write_protocols/\n",
    "    \"\"\"\n",
    "\n",
    "    epoch = UTC.localize(datetime.utcfromtimestamp(0))\n",
    "\n",
    "    timestamp = int((parse(date) - epoch).total_seconds() * 1e9)\n",
    "\n",
    "    return timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(key):\n",
    "    \"\"\" Perform the mapping between SQuaSH metadata and InfluxDB \n",
    "        given a MAPPING.\n",
    "    \n",
    "        Parameters\n",
    "        ---------- \n",
    "        key: `str`\n",
    "            The key to look for in the MAPPING.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        mapped_key: `str` or `None`       \n",
    "            Returns the `mapped_key` if the key is found in the MAPPING or the \n",
    "            original key if the key does not match.\n",
    "       \n",
    "        schema: `str` or `None`\n",
    "            The InfluxDB schema to write, or `None` if the key should not \n",
    "            be added to InfluxDB. \n",
    "        \n",
    "        \n",
    "    \"\"\" \n",
    "    mapped_key = key\n",
    "    schema = 'tag'\n",
    "    \n",
    "    for m in MAPPING:\n",
    "        if m['squash'] == key:\n",
    "            mapped_key = m['influxdb']\n",
    "            schema = m['schema']\n",
    "            break\n",
    "                \n",
    "    return mapped_key, schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(obj):\n",
    "    \"\"\" Return a valid string representing a tag key, a tag value or a field key.\n",
    "        \n",
    "        See https://docs.influxdata.com/influxdb/v0.13/write_protocols/\n",
    "        write_syntax/#escaping-characters\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        obj: `<obj>`\n",
    "            An object for the tag key, tag value or field key.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        string: `str`\n",
    "            A valid string for the tag key, tag value or field key.\n",
    "    \"\"\"\n",
    "    string = str(obj)\n",
    "    string = string.replace(\" \", \"\\ \")\n",
    "    string = string.replace(\",\", \"\\,\" )\n",
    "    string = string.replace(\"=\", \"\\=\")\n",
    "            \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_metadata(data):\n",
    "    \"\"\" Process SQuaSH metadata using a pre-configured mapping to InfluxDB.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: `dict`\n",
    "            A dictionary with SQuaSH metadata.\n",
    "       \n",
    "        Return\n",
    "        ------\n",
    "        tags: `<list>` \n",
    "            List of tags to be written to InfluxDB.\n",
    "        fields: `<list>`\n",
    "            List of fields to be written to InfluxDB.\n",
    "    \"\"\"\n",
    "    tags = []\n",
    "    fields = []\n",
    "    for key, value in data.items():\n",
    "        # process nested dict\n",
    "        if isinstance(value, dict):\n",
    "            tmp_tags, tmp_fields = process_metadata(value)\n",
    "            tags.extend(tmp_tags)\n",
    "            fields.extend(tmp_fields)\n",
    "        else:\n",
    "            new_key, schema = mapping(key)\n",
    "            if new_key and schema == 'tag':\n",
    "                tags.append(\"{}={}\".format(sanitize(new_key), sanitize(value)))\n",
    "            elif new_key and schema == 'field':\n",
    "                fields.append(\"{}={}\".format(sanitize(new_key), value))\n",
    "    \n",
    "    return tags, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_influxdb_line(measurement, tags, fields, timestamp):\n",
    "    \"\"\" Format a line following the InfluxDB line protocol.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        measurement: `<str>`\n",
    "            Name of the InfluxDB measurement\n",
    "        tags: `<list>`\n",
    "            A list of valid InfluxDB tags\n",
    "        fields: `<list>`\n",
    "            A list of valid InfluxDB fields\n",
    "        timestamp: `int`\n",
    "            A timestamp in nanosecond-precision Unix time.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        influxdb_line: `<str>`\n",
    "            An InfluxDB line as defined by the line protocol in\n",
    "            https://docs.influxdata.com/influxdb/v1.6/write_protocols/\n",
    "    \"\"\"\n",
    "    line = \"{},{} {} {}\".format(measurement, \",\".join(tags), \",\".join(fields),\n",
    "                                timestamp)\n",
    "    return line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_influxdb(influxdb_line):\n",
    "    \"\"\" Send a line to an InfluxDB database. It assumes INFLUXDB_DATABASE already\n",
    "        exists in InfluxDB.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        influxdb_line: `<str>`\n",
    "            An InfluxDB line as defined by the line protocol in\n",
    "            https://docs.influxdata.com/influxdb/v1.6/write_protocols/\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        status_code: `<int>`\n",
    "            Status code from the InfluxDB HTTP API.\n",
    "        text: `<str>`\n",
    "            Status message from the InfluxDB HTTP API.\n",
    "    \"\"\"\n",
    "    params = {'db': INFLUXDB_DATABASE}\n",
    "    r = requests.post(url=INFLUXDB_API_URL + \"/write\", params=params,\n",
    "                      data=influxdb_line)\n",
    "\n",
    "    return r.status_code, r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def job_to_influxdb(data):\n",
    "    \"\"\"Unpack a SQuaSH job and send it to InfluxDB. \n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: `<dict>`\n",
    "            A dictionary containing the job data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        status_code: `<int>`\n",
    "             204:\n",
    "               The request was processed successfully\n",
    "             400:\n",
    "               Malformed syntax or bad query\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        `lsst.verify` measurement and InfluxDB measurement mean different things. \n",
    "    \"\"\"    \n",
    "    # This still gets the timestamp of an individual `lsst.verify` job, we want \n",
    "    # the timestamp of the Jenkins job instead.\n",
    "    # DM-XXXX - SQuaSH API /jenkins/<ci_id> should return the jenkins timestamp \n",
    "    timestamp = format_timestamp(data['date_created'])\n",
    "    \n",
    "    # Add extra metadata\n",
    "    \n",
    "    data['meta']['id'] = data['id']\n",
    "    data['meta']['env']['timestamp'] = timestamp\n",
    "    data['meta']['env']['ci_dataset'] = data['ci_dataset']\n",
    "    \n",
    "    tags, extra_fields = process_metadata(data['meta'])\n",
    "    \n",
    "    # `lsst.verify` package -> InfluxDB measurement\n",
    "    # `lsst.verify` metric value -> InfluxDB field\n",
    "    # Group InfluxDB fields by the corresponding InfluxDB measurement\n",
    "    \n",
    "    fields_by_measurement = {}\n",
    "    for verify_measurement in data['measurements']:\n",
    "        # DM-XXXX - SQuaSH API /measurements should return the verification package \n",
    "        influxdb_measurement = verify_measurement['metric'].split('.')[0]\n",
    "\n",
    "        if influxdb_measurement not in fields_by_measurement:\n",
    "            fields_by_measurement[influxdb_measurement] = []\n",
    "            \n",
    "        # InfluxDB does not store NaNs\n",
    "        # https://github.com/influxdata/influxdb/issues/4089\n",
    "        if not math.isnan(verify_measurement['value']):\n",
    "            fields_by_measurement[influxdb_measurement].append(\"{}={}\".format(verify_measurement['metric'],\n",
    "                                                                              verify_measurement['value']))\n",
    "    \n",
    "    # By grouping InfluxDB fields we can also send all fields that belong to a \n",
    "    # measurement at once.\n",
    "    for influxdb_measurement in fields_by_measurement:\n",
    "    \n",
    "        fields = fields_by_measurement[influxdb_measurement] + extra_fields\n",
    "        influxdb_line = format_influxdb_line(influxdb_measurement, tags, fields,\n",
    "                                             timestamp)\n",
    "\n",
    "        status_code, message = send_to_influxdb(influxdb_line)\n",
    "        if status_code != 204:\n",
    "            print(message)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a list of verification jobs from SQuaSH and send them to InfluxDB. As you run this notebook you might follow the data being written to InfluxDB using the [Data Explorer tool](https://chronograf-demo.lsst.codes/) in Chronograf. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending InfluxDB line for job 3254.\n",
      "Sending InfluxDB line for job 3255.\n",
      "Sending InfluxDB line for job 3256.\n",
      "Sending InfluxDB line for job 3257.\n",
      "Sending InfluxDB line for job 3258.\n",
      "Sending InfluxDB line for job 3259.\n",
      "Sending InfluxDB line for job 3260.\n",
      "Sending InfluxDB line for job 3261.\n",
      "Sending InfluxDB line for job 3262.\n",
      "Sending InfluxDB line for job 3263.\n",
      "Sending InfluxDB line for job 3264.\n",
      "Sending InfluxDB line for job 3265.\n",
      "Sending InfluxDB line for job 3266.\n",
      "Sending InfluxDB line for job 3267.\n",
      "Sending InfluxDB line for job 3268.\n",
      "Sending InfluxDB line for job 3269.\n",
      "Sending InfluxDB line for job 3270.\n",
      "Sending InfluxDB line for job 3271.\n",
      "Sending InfluxDB line for job 3272.\n",
      "Sending InfluxDB line for job 3273.\n",
      "Sending InfluxDB line for job 3274.\n",
      "Sending InfluxDB line for job 3275.\n",
      "Sending InfluxDB line for job 3276.\n",
      "Sending InfluxDB line for job 3277.\n",
      "Sending InfluxDB line for job 3278.\n",
      "Sending InfluxDB line for job 3279.\n",
      "Sending InfluxDB line for job 3280.\n",
      "Sending InfluxDB line for job 3281.\n",
      "Sending InfluxDB line for job 3282.\n",
      "Sending InfluxDB line for job 3283.\n",
      "Sending InfluxDB line for job 3284.\n",
      "Sending InfluxDB line for job 3285.\n",
      "Sending InfluxDB line for job 3286.\n",
      "Sending InfluxDB line for job 3287.\n",
      "Sending InfluxDB line for job 3288.\n",
      "Sending InfluxDB line for job 3289.\n",
      "Sending InfluxDB line for job 3290.\n",
      "Sending InfluxDB line for job 3291.\n",
      "Sending InfluxDB line for job 3292.\n",
      "Sending InfluxDB line for job 3293.\n",
      "Sending InfluxDB line for job 3294.\n",
      "Sending InfluxDB line for job 3295.\n",
      "Sending InfluxDB line for job 3296.\n",
      "Sending InfluxDB line for job 3297.\n",
      "Sending InfluxDB line for job 3298.\n",
      "Sending InfluxDB line for job 3299.\n",
      "Sending InfluxDB line for job 3300.\n",
      "Sending InfluxDB line for job 3301.\n",
      "Sending InfluxDB line for job 3302.\n",
      "Sending InfluxDB line for job 3303.\n",
      "Sending InfluxDB line for job 3304.\n",
      "Sending InfluxDB line for job 3305.\n",
      "Sending InfluxDB line for job 3306.\n",
      "Sending InfluxDB line for job 3307.\n",
      "Sending InfluxDB line for job 3308.\n",
      "Sending InfluxDB line for job 3309.\n"
     ]
    }
   ],
   "source": [
    "jobs = requests.get(SQUASH_API_URL + \"/jobs\").json()\n",
    "\n",
    "for job_id in jobs['ids']:\n",
    "    \n",
    "    data = requests.get(SQUASH_API_URL + \"/job/{}\".format(job_id)).json()\n",
    "    \n",
    "    # Skip deprecated datasets\n",
    "    if data['ci_dataset'] == 'unknown' or data['ci_dataset'] == 'decam':\n",
    "        continue\n",
    "\n",
    "    print('Sending InfluxDB line for job {}.'.format(job_id))\n",
    "    \n",
    "    job_to_influxdb(data)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
