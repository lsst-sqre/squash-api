{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQuaSH InfluxDB data model\n",
    "\n",
    "In [DM-16775](https://github.com/lsst-sqre/squash-restful-api/tree/master/examples/influxdb_data_model.ipynb) we revisit the SQuaSH InfluxDB data model. You can use this notebook to try different strategies when mapping SQuaSH data to InfluxDB. You can also use it to \"manually\" synchronize the SQuaSH production database with an InfluxDB instance. For a quick introduction on InfluxDB concepts see [this notebook](https://github.com/lsst-sqre/influx-demo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUASH_API_URL = \"https://squash-restful-api.lsst.codes/\"\n",
    "INFLUXDB_API_URL = \"https://influxdb-demo.lsst.codes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells will grab SQuaSH data and write them in the format used by InfluxDB, the so called [line protocol](https://docs.influxdata.com/influxdb/v1.6/write_protocols/line_protocol_tutorial/):\n",
    "\n",
    "\n",
    "```#<measurement>[,<tag_key>=<tag_value>[,<tag_key>=<tag_value>]] <field_key>=<field_value>[,<field_key>=<field_value>] [<timestamp>]```\n",
    "\n",
    "Important InfluxDB concepts are: \n",
    "\n",
    "  * An InfluxDB measurement is equivalent to an SQL table;\n",
    "  * An InfluxDB tag is equivalent to an indexed column, tags are typically metadata and are used in query predicates are annotations that are used to query the data, and thus are indexed in InfluxDB;\n",
    "  * An InfluxDB field corresponds to a non-indxed column, fields typically have the values you are interested in, like the metric values in this context.\n",
    "  * InfluxDB is optimized for time-series data which are indexed and sharded by the timestamp.\n",
    "\n",
    "## Mapping lsst.verify concepts to InfluxDB\n",
    "\n",
    "`lsst.verify` concepts are mapped as follow:\n",
    "\n",
    "  * lsst.verify package -> InfluxDB measurement;\n",
    "  * lsst.verify metadata -> InfluxDB tags or fields (see next section);\n",
    "  * lsst.verify metric name -> InfluxDB field key;\n",
    "  * lsst.verify metric value -> InfluxDB field value;\n",
    "  * CI or LDF pipeline runtime -> InfluxDB timestamp.\n",
    "  \n",
    "**Note**: we avoid using lsst.verify \"measurement\" here and use \"metric value\" instead to avoid collision with InfluxDB measurement which means a completely different thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping SQuaSH metadata to InfluxDB\n",
    "`lsst.verify` adds metadata to the verification jobs uploaded to SQuaSH. The mapping of these metadata to either InfluxDB tags or fields is defined here:\n",
    "\n",
    "1. `schema` defines how the SQuaSH metadata is mapped to an InfluxDB. It can be `tag` or `field` or `None`. If `schema` is set to `None`, then the metadata is dropped and won't be written to InfluxDB.\n",
    "2. You can use the mapping to rename a metadata key when appropriate. \n",
    "3. By default, if the SQuaSH metadata key is not found in the mapping, the original key is preserved and it is written to InfluxDB as a tag.\n",
    "4. Finally, it is also possible to define a transformation on the streaming data. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = [{'squash': 'ci_id',  # The ID of the execution environment is mapped to run_id\n",
    "            'influxdb': 'run_id', \n",
    "            'schema': 'field'\n",
    "           },\n",
    "           {'squash': 'run_id',\n",
    "            'influxdb': 'run_id',\n",
    "            'schema': 'field'\n",
    "           },\n",
    "            {'squash': 'id',  \n",
    "            'influxdb': 'squash_id',\n",
    "            'schema': 'field'\n",
    "           },\n",
    "            {'squash': 'url',\n",
    "             'influxdb': 'squash_url',\n",
    "             'schema': 'field',\n",
    "             'transformation': \"format_url(data['id'], value)\"\n",
    "            },\n",
    "           {'squash': 'run_id_url', # The URL of the execution environment is mapped to run_url\n",
    "            'influxdb': 'run_url',\n",
    "            'schema': 'field',\n",
    "            'transformation': \"format_url(data['run_id'], value)\"\n",
    "           },\n",
    "           {'squash': 'ci_url',\n",
    "            'influxdb': 'run_url',\n",
    "            'schema': 'field',\n",
    "            'transformation': \"format_url(data['ci_id'], value)\"\n",
    "           },\n",
    "           {'squash': 'ci_dataset', # The processed dataset is mapped to dataset\n",
    "            'influxdb': 'dataset',\n",
    "            'schema': 'tag'\n",
    "           },\n",
    "           {'squash': 'version_tag', \n",
    "            'influxdb': 'version_tag',\n",
    "            'schema': 'field'\n",
    "           },\n",
    "           {'squash': 'filter_name',\n",
    "            'influxdb': 'filter',\n",
    "            'schema': 'tag'\n",
    "           },\n",
    "           {'squash': 'date_created',\n",
    "            'influxdb': 'timestamp',\n",
    "            'schema': 'field',\n",
    "            'transformation': 'format_timestamp(value)'\n",
    "           },\n",
    "           {'squash': 'date', \n",
    "            'influxdb': None,\n",
    "            'schema': None\n",
    "           },\n",
    "           {'squash': 'ci_label',\n",
    "            'influxdb': None,\n",
    "            'schema': None\n",
    "           },\n",
    "           {'squash': 'ci_name',\n",
    "            'influxdb': 'pipeline',\n",
    "            'schema': 'tag'\n",
    "           },\n",
    "           {'squash': 'code_changes',\n",
    "            'influxdb': 'code_changes',\n",
    "            'schema': 'field',\n",
    "            'transformation': \"format_code_changes(data['ci_id'], data['ci_name'])\"\n",
    "           },\n",
    "           \n",
    "           {'squash': 'code_changes_counts',\n",
    "            'influxdb': 'code_changes_counts',\n",
    "            'schema': 'field',\n",
    "            'transformation': \"format_code_changes_counts(data['ci_id'], data['ci_name'])\"\n",
    "           },\n",
    "           {'squash': 'packages',\n",
    "            'influxdb': None,\n",
    "            'schema': None}\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rationale for this mapping is the following:\n",
    "1. The reason for mapping `ci_id`, `run_id`, `squash_id`, `ci_url` and `run_id_url` to InfluxDB fields is to [reduce InfluxDB series cardinality](https://docs.influxdata.com/influxdb/v1.7/concepts/schema_and_data_layout/#discouraged-schema-design). `ci_id`, `run_id` and `squash_id` are sequential ids and `ci_url` and `run_id_url` are also different for each run (DM-18342). We also want to track these information so they must be stored as fields.\n",
    "2. We define a common data model for mapping variables from different execution environments, for example, `ci_id` and `run_id` to `run_id`, `ci_url` and `run_id_url` to `run_url`, `ci_dataset` and `dataset` to `dataset`. The corresponding values can be filtered by the `env_name` tag. \n",
    "3. It is not possible to do [math operations with InfluxDB timestamps](https://community.influxdata.com/t/math-operations-on-field-value-and-time/6323/4) so it is useful to add the `timestamp` explicitly as a field. There's also a `date` field which is added as environment metadata that we don't need in InfluxDB (DM-17049)\n",
    "4. `lsst.verify` metadata uses `filter_name`. We decided to rename it since it is commonly called filter in the dataID used in DM pipeline software.\n",
    "5. `ci_label` does not seem important so we skip that.\n",
    "6. `ci_name` is mapped to `pipeline`. It identifies the pipeline that was executed. Some pipelines can have several verication packages (or InfluxDB mesasurements), so with the pipeline tag we can distinguish them.\n",
    "7. We add the code changes information for pipelines that run in the Jenkins environment.\n",
    "8. We also skip `packages` metadata for now. \n",
    "9. Metadata not listed in this mapping is automatically added as InfluxDB tags.\n",
    "\n",
    "\n",
    "See also [InfluxDB schema design and data layout](https://docs.influxdata.com/influxdb/v1.7/concepts/schema_and_data_layout/#general-recommendations) for general recommendations on designing the InfluxDB schema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a new InfluxDB database. If the database already exists, an status code 200 (OK) is returned, and the existing data is preserved. If you want to overwrite an existing database you have to delete it first using the Chronograf admin interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "INFLUXDB_DATABASE = \"squash-demo\"\n",
    "\n",
    "params={'q': 'CREATE DATABASE \"{}\"'.format(INFLUXDB_DATABASE)}\n",
    "r = requests.post(url=INFLUXDB_API_URL + \"/query\", params=params)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytz import UTC\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def format_timestamp(date):\n",
    "    \"\"\" Format a timestamp string to be used in the InfluxDB line protocol.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        date: `<str>`\n",
    "            Timestamp string, e.g. 2019-02-11T19:06:32Z\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        timestamp: `<int>`\n",
    "            Timestamp in nanosecond-precision Unix time.\n",
    "            See https://docs.influxdata.com/influxdb/v1.6/write_protocols/\n",
    "    \"\"\"\n",
    "\n",
    "    epoch = UTC.localize(datetime.utcfromtimestamp(0))\n",
    "\n",
    "    timestamp = int((parse(date) - epoch).total_seconds() * 1e9)\n",
    "\n",
    "    return timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_url(title, url):\n",
    "    return \"[{}]({})\".format(title, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_code_changes(ci_id, ci_name):\n",
    "\n",
    "    data = requests.get(SQUASH_API_URL + \"/code_changes/{}?ci_name={}\".format(ci_id, ci_name)).json()\n",
    "    \n",
    "    code_changes = []\n",
    "    for pkg in data['packages']:\n",
    "        name = pkg[0]\n",
    "        git_sha = pkg[1]\n",
    "        git_url = pkg[2]\n",
    "        git_commit_url = git_url.replace('.git','/commit/')+git_sha\n",
    "        code_changes.append(format_url(name, git_commit_url))\n",
    "        \n",
    "    return \", \".join(code_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_code_changes_counts(ci_id, ci_name):\n",
    "    data = requests.get(SQUASH_API_URL + \"/code_changes/{}?ci_name={}\".format(ci_id, ci_name)).json()\n",
    "    \n",
    "    code_changes_counts = 0\n",
    "    if data['counts']:\n",
    "        code_changes_counts = data['counts']\n",
    "    \n",
    "    return code_changes_counts\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(key):\n",
    "    \"\"\" Perform the mapping between SQuaSH metadata and InfluxDB \n",
    "        given a MAPPING.\n",
    "    \n",
    "        Parameters\n",
    "        ---------- \n",
    "        key: `str`\n",
    "            The key to look for in the MAPPING.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        mapped_key: `str` or `None`       \n",
    "            Returns the `mapped_key` if the key is found in the MAPPING or the \n",
    "            original key if the key does not match.\n",
    "       \n",
    "        schema: `str` or `None`\n",
    "            The InfluxDB schema to write, or `None` if the key should not \n",
    "            be added to InfluxDB. \n",
    "        \n",
    "        \n",
    "    \"\"\" \n",
    "    schema = 'tag'\n",
    "    mapped_key = key\n",
    "    transformation = None\n",
    "    \n",
    "    for m in MAPPING:\n",
    "        if m['squash'] == key:\n",
    "            mapped_key = m['influxdb']\n",
    "            schema = m['schema']\n",
    "            if 'transformation' in m:\n",
    "                transformation = m['transformation']\n",
    "            break\n",
    "                \n",
    "    return schema, mapped_key, transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(obj):\n",
    "    \"\"\" Return a valid string representing a tag key, a tag value or a field key.\n",
    "        \n",
    "        See https://docs.influxdata.com/influxdb/v0.13/write_protocols/\n",
    "        write_syntax/#escaping-characters\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        obj: `<obj>`\n",
    "            An object for the tag key, tag value or field key.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        string: `str`\n",
    "            A valid string for the tag key, tag value or field key.\n",
    "    \"\"\"\n",
    "    string = str(obj)\n",
    "    string = string.replace(\" \", \"_\")\n",
    "    string = string.replace(\",\", \"\\,\" )\n",
    "    string = string.replace(\"=\", \"\\=\")\n",
    "            \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_metadata(data):\n",
    "    \"\"\" Process SQuaSH metadata using a pre-configured mapping to InfluxDB.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: `dict`\n",
    "            A dictionary with SQuaSH metadata.\n",
    "       \n",
    "        Return\n",
    "        ------\n",
    "        tags: `<list>` \n",
    "            List of tags to be written to InfluxDB.\n",
    "        fields: `<list>`\n",
    "            List of fields to be written to InfluxDB.\n",
    "    \"\"\"\n",
    "    tags = []\n",
    "    fields = []\n",
    "    for key, value in data.items():\n",
    "        # process nested dict\n",
    "        if isinstance(value, dict):\n",
    "            tmp_tags, tmp_fields = process_metadata(value)\n",
    "            tags.extend(tmp_tags)\n",
    "            fields.extend(tmp_fields)\n",
    "        else:\n",
    "            schema, mapped_key, transformation = mapping(key)\n",
    "            if transformation:\n",
    "                value = eval(transformation)\n",
    "            if mapped_key and schema == 'tag':\n",
    "                tags.append(\"{}={}\".format(sanitize(mapped_key), sanitize(value)))\n",
    "            elif mapped_key and schema == 'field':\n",
    "                if isinstance(value, str):\n",
    "                    fields.append(\"{}=\\\"{}\\\"\".format(sanitize(mapped_key), value))\n",
    "                else:\n",
    "                    fields.append(\"{}={}\".format(sanitize(mapped_key), value))\n",
    "    \n",
    "    return tags, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_influxdb_line(measurement, tags, fields, timestamp):\n",
    "    \"\"\" Format a line following the InfluxDB line protocol.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        measurement: `<str>`\n",
    "            Name of the InfluxDB measurement\n",
    "        tags: `<list>`\n",
    "            A list of valid InfluxDB tags\n",
    "        fields: `<list>`\n",
    "            A list of valid InfluxDB fields\n",
    "        timestamp: `int`\n",
    "            A timestamp in nanosecond-precision Unix time.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        influxdb_line: `<str>`\n",
    "            An InfluxDB line as defined by the line protocol in\n",
    "            https://docs.influxdata.com/influxdb/v1.6/write_protocols/\n",
    "    \"\"\"\n",
    "    line = \"{},{} {} {}\".format(measurement, \",\".join(tags), \",\".join(fields),\n",
    "                                timestamp)\n",
    "    return line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_influxdb(influxdb_line):\n",
    "    \"\"\" Send a line to an InfluxDB database. It assumes the INFLUXDB_DATABASE already\n",
    "        exists in InfluxDB.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        influxdb_line: `<str>`\n",
    "            An InfluxDB line as defined by the line protocol in\n",
    "            https://docs.influxdata.com/influxdb/v1.6/write_protocols/\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        status_code: `<int>`\n",
    "            Status code from the InfluxDB HTTP API.\n",
    "        text: `<str>`\n",
    "            Status message from the InfluxDB HTTP API.\n",
    "    \"\"\"\n",
    "    params = {'db': INFLUXDB_DATABASE}\n",
    "    r = requests.post(url=INFLUXDB_API_URL + \"/write\", params=params,\n",
    "                      data=influxdb_line)\n",
    "\n",
    "    return r.status_code, r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import urllib.parse\n",
    "\n",
    "def job_to_influxdb(data):\n",
    "    \"\"\"Unpack a lsst.verify job and send it to InfluxDB. \n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: `<dict>`\n",
    "            A dictionary containing the verification job data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        status_code: `<int>`\n",
    "             204:\n",
    "               The request was processed successfully\n",
    "             400:\n",
    "               Malformed syntax or bad query\n",
    "    \"\"\" \n",
    "    \n",
    "    if data['meta']['env']['env_name'] == 'jenkins':\n",
    "        ci_id = data['meta']['env']['ci_id']\n",
    "        ci_name = data['meta']['env']['ci_name']\n",
    "        date_created = requests.get(SQUASH_API_URL + \"/jenkins/{}?ci_name={}\".format(ci_id, ci_name)).json()['date_created']\n",
    "        timestamp = format_timestamp(date_created)\n",
    "    else:    \n",
    "        timestamp = format_timestamp(data['date_created'])\n",
    "    \n",
    "    # Add extra metadata\n",
    "    \n",
    "    data['meta']['id'] = data['id']\n",
    "    \n",
    "    data['meta']['url'] = urllib.parse.urljoin(SQUASH_API_URL, \n",
    "                                               \"/job/{}\".format(data['id']))\n",
    "\n",
    "    data['meta']['date_created'] = data['date_created']\n",
    "    data['meta']['env']['ci_dataset'] = data['ci_dataset']\n",
    "    \n",
    "    # Edge cases that we cannot handle in the mapping\n",
    "    \n",
    "    # Fix dataset_repo_url duplication\n",
    "    if 'dataset_repo_url' in data['meta'].keys():\n",
    "        del data['meta']['dataset_repo_url']\n",
    "    \n",
    "    # Fix use of ci_dataset key in environments other than jenkins\n",
    "    if data['meta']['env']['env_name'] != 'jenkins':\n",
    "        if 'ci_dataset' in data['meta']['env']:\n",
    "            del data['meta']['env']['ci_dataset']\n",
    "            \n",
    "    # add code changes \n",
    "    if data['meta']['env']['env_name'] == 'jenkins':\n",
    "        data['meta']['env']['code_changes'] = ''\n",
    "        data['meta']['env']['code_changes_counts'] = ''\n",
    "         \n",
    "        # fix ci_name until DM-18599 is not implemented\n",
    "        if 'validate_drp' in data['meta']['env']['ci_url']:\n",
    "            data['meta']['env']['ci_name'] = 'validate_drp'\n",
    "        elif 'ap_verify' in data['meta']['env']['ci_url']:\n",
    "            data['meta']['env']['ci_name'] = 'ap_verify'\n",
    "        \n",
    "    \n",
    "    tags, extra_fields = process_metadata(data['meta'])\n",
    "    \n",
    "    tags = list(set(tags))\n",
    "    \n",
    "    # `lsst.verify` package -> InfluxDB measurement\n",
    "    # `lsst.verify` metric name -> InfluxDB field name\n",
    "    # `lsst.verify` metric name -> InfluxDB field name\n",
    "    # Group InfluxDB fields by the corresponding InfluxDB measurement\n",
    "    \n",
    "    fields_by_measurement = {}\n",
    "    for verify_measurement in data['measurements']:\n",
    "        # DM-18360 - SQuaSH API /measurements should return the verification package \n",
    "        influxdb_measurement = verify_measurement['metric'].split('.')[0]\n",
    "        \n",
    "        field_key = verify_measurement['metric'].lstrip(\"{}.\".format(influxdb_measurement))\n",
    "        field_value = verify_measurement['value']\n",
    "\n",
    "        if influxdb_measurement not in fields_by_measurement:\n",
    "            fields_by_measurement[influxdb_measurement] = []\n",
    "            \n",
    "        # InfluxDB does not store NaNs\n",
    "        # https://github.com/influxdata/influxdb/issues/4089\n",
    "        if not math.isnan(field_value):\n",
    "            fields_by_measurement[influxdb_measurement].append(\"{}={}\".format(field_key,\n",
    "                                                                              field_value))\n",
    "    \n",
    "    # By grouping InfluxDB fields we can also send all fields that belong to a \n",
    "    # measurement at once.\n",
    "    for influxdb_measurement in fields_by_measurement:\n",
    "    \n",
    "        fields = fields_by_measurement[influxdb_measurement] + extra_fields\n",
    "        influxdb_line = format_influxdb_line(influxdb_measurement, tags, fields,\n",
    "                                             timestamp)\n",
    "\n",
    "        #print(influxdb_line)\n",
    "        status_code, message = send_to_influxdb(influxdb_line)\n",
    "        if status_code != 204:\n",
    "            print(message)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending verification jobs from the SQuaSH API to InfluxDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a list of verification jobs from SQuaSH and send them to InfluxDB. As you run this notebook you might follow the data being written to InfluxDB using the [Data Explorer tool](https://squash.lsst.codes/) in Chronograf. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = requests.get(SQUASH_API_URL + \"/jobs\").json()\n",
    "\n",
    "for job_id in jobs['ids']:\n",
    "    \n",
    "    if int(job_id) >= 8443:\n",
    "        \n",
    "        data = requests.get(SQUASH_API_URL + \"/job/{}\".format(job_id)).json()\n",
    "    \n",
    "        dataset = data['ci_dataset']\n",
    "        \n",
    "        if dataset != 'HSC RC2':\n",
    "            print(f\"Skipping dataset {dataset}.\")\n",
    "            continue\n",
    "\n",
    "        print(f'Sending InfluxDB line for job {job_id} dataset {dataset}.')\n",
    "    \n",
    "        job_to_influxdb(data)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
